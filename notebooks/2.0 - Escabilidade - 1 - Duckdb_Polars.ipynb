{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb8fa97",
   "metadata": {},
   "source": [
    "# CSV vs PARQUET (Arrow)\n",
    "\n",
    "- format scalability\n",
    "- using local DuckDB\n",
    "- with MovieLens 100k and 33M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79fc4dc",
   "metadata": {},
   "source": [
    "## Setup — Imports & Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5cd968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths defined successfully.\n",
      "DuckDB connection opened.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "#   IMPORTS & PATHS & SETUP\n",
    "# ===============================================\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# === PATHS FOR THE DATASETS ===\n",
    "\n",
    "## MovieLens 100k\n",
    "DATA_100k = Path(\"..\") / \"data\" / \"100K\"\n",
    "ratings_100k = DATA_100k / \"ratings.csv\"\n",
    "movies_100k  = DATA_100k / \"movies.csv\"\n",
    "tags_100k    = DATA_100k / \"tags.csv\"\n",
    "links_100k   = DATA_100k / \"links.csv\"\n",
    "\n",
    "## MovieLens 33M\n",
    "DATA_33m = Path(\"..\") / \"data\" / \"Full33M\"\n",
    "ratings_33m = DATA_33m / \"ratings.csv\"\n",
    "movies_33m  = DATA_33m / \"movies.csv\"\n",
    "tags_33m    = DATA_33m / \"tags.csv\"\n",
    "links_33m   = DATA_33m / \"links.csv\"\n",
    "\n",
    "print(\"Paths defined successfully.\")\n",
    "\n",
    "# === Local DuckDB connection ===\n",
    "con = duckdb.connect(\"movielens_local.duckdb\")\n",
    "print(\"DuckDB connection opened.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35af9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\100K\\ratings.csv\n",
      "..\\data\\Full33M\\ratings.csv\n"
     ]
    }
   ],
   "source": [
    "print(ratings_100k)\n",
    "print(ratings_33m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ceffa",
   "metadata": {},
   "source": [
    "## Create Parquet Tables in DuckDB (ratings_parquet, movies_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a4740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet paths:\n",
      "..\\data\\100K\\ratings.parquet\n",
      "..\\data\\Full33M\\ratings.parquet\n",
      "..\\data\\Full33M\\movies.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfd3319714b42ea9214b3f0c8ee9b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV -> Parquet conversion finished.\n"
     ]
    }
   ],
   "source": [
    "# === CONVERSÃO CSV -> PARQUET  ===\n",
    "\n",
    "ratings_100k_parquet = ratings_100k.with_suffix(\".parquet\")\n",
    "ratings_33m_parquet  = ratings_33m.with_suffix(\".parquet\")\n",
    "movies_33m_parquet   = movies_33m.with_suffix(\".parquet\")\n",
    "\n",
    "print(\"Parquet paths:\")\n",
    "print(ratings_100k_parquet)\n",
    "print(ratings_33m_parquet)\n",
    "print(movies_33m_parquet)\n",
    "\n",
    "# Converter apenas se precisares (simples: corre sempre para já)\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_100k}'))\n",
    "TO '{ratings_100k_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_33m}'))\n",
    "TO '{ratings_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{movies_33m}'))\n",
    "TO '{movies_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "print(\"CSV -> Parquet conversion finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3d809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movies_33m_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ratings_100k_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ratings_33m_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ratings_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tags_parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name\n",
       "0    movies_33m_parquet\n",
       "1  ratings_100k_parquet\n",
       "2   ratings_33m_parquet\n",
       "3       ratings_parquet\n",
       "4          tags_parquet"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === VIEWS DuckDB sobre os ficheiros Parquet ===\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW ratings_100k_parquet AS\n",
    "    SELECT * FROM read_parquet('{ratings_100k_parquet}')\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW ratings_33m_parquet AS\n",
    "    SELECT * FROM read_parquet('{ratings_33m_parquet}')\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW movies_33m_parquet AS\n",
    "    SELECT * FROM read_parquet('{movies_33m_parquet}')\n",
    "\"\"\")\n",
    "\n",
    "con.sql(\"SHOW TABLES\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8dfd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função medir_tempo\n",
    "\n",
    "def medir_tempo(query):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(query).df()\n",
    "    return round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaf437",
   "metadata": {},
   "source": [
    "## Benchmark 1 — CSV vs Parquet Performance (AVG ratings + GROUP BY moviesId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ebe3",
   "metadata": {},
   "source": [
    "We measure the execution time of a simple aggregation query (`AVG(rating)` grouped by `movieId`) on CSV and Parquet, for both MovieLens 100k and 33M. This isolates the impact of the storage format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e9623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba2b63a9c7c4f0488901c4fc38acbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'CSV_100k': 0.078,\n",
       " 'PARQUET_100k': 0.018,\n",
       " 'CSV_33M': 2.207,\n",
       " 'PARQUET_33M': 0.212}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medições CSV vs Parquet\n",
    "\n",
    "tempos = {\n",
    "    \"CSV_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k.with_suffix('.parquet')}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"CSV_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m.with_suffix('.parquet')}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "}\n",
    "\n",
    "tempos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a067f54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>CSV time (s)</th>\n",
       "      <th>Parquet time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33M</td>\n",
       "      <td>2.207</td>\n",
       "      <td>0.212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  CSV time (s)  Parquet time (s)\n",
       "0    100k         0.078             0.018\n",
       "1     33M         2.207             0.212"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela comparativa\n",
    "\n",
    "df_tempo = pd.DataFrame([\n",
    "    [\"100k\", tempos[\"CSV_100k\"], tempos[\"PARQUET_100k\"]],\n",
    "    [\"33M\", tempos[\"CSV_33M\"], tempos[\"PARQUET_33M\"]],\n",
    "], columns=[\"Dataset\", \"CSV time (s)\", \"Parquet time (s)\"])\n",
    "\n",
    "df_tempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c46e60",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "This benchmark measures the execution time of a simple aggregation query (`AVG(rating)` grouped by `movieId`) across four scenarios:\n",
    "\n",
    "- CSV 100K\n",
    "- Parquet 100K\n",
    "- CSV 33M\n",
    "- Parquet 33M\n",
    "\n",
    "The results show the strong impact of storage format on query speed, with Parquet providing substantial improvements—especially at larger scales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0717edf6",
   "metadata": {},
   "source": [
    "__Close the connection (when done)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da0104a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con.close()\n",
    "#print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4aa39",
   "metadata": {},
   "source": [
    "# DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d6dc5",
   "metadata": {},
   "source": [
    "## Benchmark 2 — Simple COUNT() Query (DuckDB vs Polars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda6b7a",
   "metadata": {},
   "source": [
    "Here we run the same aggregation query (`AVG(rating)` grouped by `movieId`) on Parquet files using DuckDB and Polars, for 100k and 33M rows, in order to compare the execution engines under a simple workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97aa5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths para Parquet\n",
    "\n",
    "p100k = ratings_100k.with_suffix(\".parquet\")\n",
    "p33m = ratings_33m.with_suffix(\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9274a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de benchmark\n",
    "\n",
    "def run_duckdb(path):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{path}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\").df()\n",
    "    return round(time.time() - t0, 3)\n",
    "\n",
    "def run_polars(path):\n",
    "    t0 = time.time()\n",
    "    (\n",
    "        pl.scan_parquet(str(path))     \n",
    "          .group_by(\"movieId\")         \n",
    "          .agg(pl.col(\"rating\").mean())\n",
    "          .collect()\n",
    "    )\n",
    "    return round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e96088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33m</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  DuckDB (s)  Polars (s)\n",
       "0    100k       0.007       0.123\n",
       "1     33m       0.171       0.605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparação\n",
    "\n",
    "df_duck_polars = pd.DataFrame([\n",
    "    [\"100k\", run_duckdb(p100k), run_polars(p100k)],\n",
    "    [\"33m\", run_duckdb(p33m), run_polars(p33m)],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_duck_polars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39228",
   "metadata": {},
   "source": [
    "## Benchmark 3 — Aggregation + JOIN (AVG, COUNT, STDDEV) — DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707409",
   "metadata": {},
   "source": [
    "This benchmark uses a more realistic analytical workload on the 33M dataset:\n",
    "we compute average rating, number of ratings and standard deviation per movie, join with the movies table to retrieve titles, filter movies with at least 500 ratings, and sort by total_ratings (TOP 100). The goal is to compare DuckDB and Polars under a heavier analytical query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb8192f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RATINGS = 500\n",
    "\n",
    "def run_duckdb_movie_stats(con):\n",
    "    sql = f\"\"\"\n",
    "    WITH movie_stats AS (\n",
    "        SELECT\n",
    "            m.movieId,\n",
    "            m.title,\n",
    "            AVG(r.rating) AS avg_rating,\n",
    "            COUNT(*) AS total_ratings,\n",
    "            STDDEV_POP(r.rating) AS std_rating\n",
    "        FROM ratings_33m_parquet r\n",
    "        JOIN movies_33m_parquet m USING (movieId)\n",
    "        GROUP BY m.movieId, m.title\n",
    "        HAVING COUNT(*) >= {MIN_RATINGS}\n",
    "    )\n",
    "    SELECT\n",
    "        movieId,\n",
    "        title,\n",
    "        ROUND(avg_rating, 3)  AS avg_rating,\n",
    "        total_ratings,\n",
    "        ROUND(std_rating, 3)  AS std_rating\n",
    "    FROM movie_stats\n",
    "    ORDER BY total_ratings DESC\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    return con.sql(sql).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14668867",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "\n",
    "#df_duckdb_stats.head(), t_duckdb_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05aa519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "\n",
    "#df_duckdb_stats.head(), t_duckdb_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5b521fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4fddad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_polars_movie_stats_33m():\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # usar os ficheiros PARQUET, não os CSV\n",
    "    ratings = (\n",
    "        pl.scan_parquet(str(ratings_33m_parquet))\n",
    "        .select([\"movieId\", \"rating\"])\n",
    "    )\n",
    "\n",
    "    movies  = (\n",
    "        pl.scan_parquet(str(movies_33m_parquet))\n",
    "        .select([\"movieId\", \"title\"])\n",
    "    )\n",
    "\n",
    "    MIN_RATINGS = 500\n",
    "\n",
    "    result = (\n",
    "        ratings\n",
    "        .group_by(\"movieId\")\n",
    "        .agg([\n",
    "            pl.col(\"rating\").mean().alias(\"avg_rating\"),\n",
    "            pl.count().alias(\"total_ratings\"),\n",
    "            pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "        ])\n",
    "        .filter(pl.col(\"total_ratings\") >= MIN_RATINGS)\n",
    "        .join(movies, on=\"movieId\")\n",
    "        .select([\n",
    "            \"movieId\",\n",
    "            \"title\",\n",
    "            pl.col(\"avg_rating\").round(3),\n",
    "            \"total_ratings\",\n",
    "            pl.col(\"std_rating\").round(3),\n",
    "        ])\n",
    "        .sort(\"total_ratings\", descending=True)\n",
    "        .limit(100)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return result, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c97ab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars_stats_33m, t_polars_stats_33m = run_polars_movie_stats_33m()\n",
    "#df_polars_stats_33m.head(), t_polars_stats_33m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc776f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33M (complex)</td>\n",
       "      <td>1.023147</td>\n",
       "      <td>0.676009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset  DuckDB (s)  Polars (s)\n",
       "0  33M (complex)    1.023147    0.676009"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complex = pd.DataFrame([\n",
    "    [\"33M (complex)\", t_duckdb_stats, t_polars_stats_33m],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_complex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90d778",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b948fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmark 1 – 100k (CSV vs Parquet)</td>\n",
       "      <td>DuckDB CSV</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benchmark 1 – 100k (CSV vs Parquet)</td>\n",
       "      <td>DuckDB Parquet</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benchmark 1 – 33M (CSV vs Parquet)</td>\n",
       "      <td>DuckDB CSV</td>\n",
       "      <td>2.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmark 1 – 33M (CSV vs Parquet)</td>\n",
       "      <td>DuckDB Parquet</td>\n",
       "      <td>0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benchmark 2 – 100k (simple)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Benchmark 2 – 100k (simple)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Benchmark 2 – 33M (simple)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benchmark 2 – 33M (simple)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Benchmark 3 – 33M (complex)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>1.023147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Benchmark 3 – 33M (complex)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.676009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Scenario          Engine  Time (s)\n",
       "0  Benchmark 1 – 100k (CSV vs Parquet)      DuckDB CSV  0.078000\n",
       "1  Benchmark 1 – 100k (CSV vs Parquet)  DuckDB Parquet  0.018000\n",
       "2   Benchmark 1 – 33M (CSV vs Parquet)      DuckDB CSV  2.207000\n",
       "3   Benchmark 1 – 33M (CSV vs Parquet)  DuckDB Parquet  0.212000\n",
       "4          Benchmark 2 – 100k (simple)          DuckDB  0.007000\n",
       "5          Benchmark 2 – 100k (simple)          Polars  0.123000\n",
       "6           Benchmark 2 – 33M (simple)          DuckDB  0.171000\n",
       "7           Benchmark 2 – 33M (simple)          Polars  0.605000\n",
       "8          Benchmark 3 – 33M (complex)          DuckDB  1.023147\n",
       "9          Benchmark 3 – 33M (complex)          Polars  0.676009"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.DataFrame([\n",
    "    [\"Benchmark 1 - 100k (CSV vs Parquet)\", \"DuckDB CSV\", tempos[\"CSV_100k\"]],\n",
    "    [\"Benchmark 1 - 100k (CSV vs Parquet)\", \"DuckDB Parquet\", tempos[\"PARQUET_100k\"]],\n",
    "    [\"Benchmark 1 - 33M (CSV vs Parquet)\", \"DuckDB CSV\", tempos[\"CSV_33M\"]],\n",
    "    [\"Benchmark 1 - 33M (CSV vs Parquet)\", \"DuckDB Parquet\", tempos[\"PARQUET_33M\"]],\n",
    "    [\"Benchmark 2 - 100k (simple)\", \"DuckDB\", df_duck_polars.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 2 - 100k (simple)\", \"Polars\", df_duck_polars.loc[0, \"Polars (s)\"]],\n",
    "    [\"Benchmark 2 - 33M (simple)\", \"DuckDB\", df_duck_polars.loc[1, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 2 - 33M (simple)\", \"Polars\", df_duck_polars.loc[1, \"Polars (s)\"]],\n",
    "    [\"Benchmark 3 - 33M (complex)\", \"DuckDB\", df_complex.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 3 - 33M (complex)\", \"Polars\", df_complex.loc[0, \"Polars (s)\"]],\n",
    "], columns=[\"Scenario\", \"Engine\", \"Time (s)\"])\n",
    "\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352502a",
   "metadata": {},
   "source": [
    "The results show that Parquet is substantially faster than CSV, delivering up to a considerable improvement on the 33M dataset.\n",
    "\n",
    "In the engine comparison (Benchmark 2), DuckDB is faster on simple aggregations—especially on smaller datasets—while Polars remains competitive.\n",
    "\n",
    "In the complex analytical query (Benchmark 3), Polars outperforms DuckDB (0.67s vs 1.02s), demonstrating better scalability under heavier workloads.\n",
    "\n",
    "Both engines achieve sub-second performance on 33M rows when using Parquet, highlighting the efficiency of columnar storage.\n",
    "\n",
    "Overall, Parquet + Polars provides the strongest performance for large-scale analytical queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
