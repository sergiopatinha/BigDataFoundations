{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8aa302",
   "metadata": {},
   "source": [
    "# Benchmark Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8fa97",
   "metadata": {},
   "source": [
    "## 1.0 CSV vs PARQUET (Arrow)\n",
    "\n",
    "- format scalability\n",
    "- using local DuckDB\n",
    "- with MovieLens 100k and 33M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79fc4dc",
   "metadata": {},
   "source": [
    "### 1.1 Setup — Imports & Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab5cd968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths defined successfully.\n",
      "DuckDB connection opened.\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "#   IMPORTS & PATHS & SETUP\n",
    "# ===============================================\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# === PATHS FOR THE DATASETS ===\n",
    "\n",
    "## MovieLens 100k\n",
    "DATA_100k = Path(\"..\") / \"data\" / \"100K\"\n",
    "ratings_100k_csv = DATA_100k / \"ratings.csv\"\n",
    "movies_100k_csv  = DATA_100k / \"movies.csv\"\n",
    "tags_100k_csv    = DATA_100k / \"tags.csv\"\n",
    "links_100k_csv   = DATA_100k / \"links.csv\"\n",
    "\n",
    "## MovieLens 33M\n",
    "DATA_33m = Path(\"..\") / \"data\" / \"Full33M\"\n",
    "ratings_33m_csv = DATA_33m / \"ratings.csv\"\n",
    "movies_33m_csv  = DATA_33m / \"movies.csv\"\n",
    "tags_33m_csv    = DATA_33m / \"tags.csv\"\n",
    "links_33m_csv   = DATA_33m / \"links.csv\"\n",
    "\n",
    "print(\"Paths defined successfully.\")\n",
    "\n",
    "# === Local DuckDB connection ===\n",
    "con = duckdb.connect(\"movielens_local.duckdb\")\n",
    "print(\"DuckDB connection opened.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35af9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\100K\\ratings.csv\n",
      "..\\data\\Full33M\\ratings.csv\n"
     ]
    }
   ],
   "source": [
    "print(ratings_100k_csv)\n",
    "print(ratings_33m_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ceffa",
   "metadata": {},
   "source": [
    "### 1.2 Create Parquet Tables in DuckDB (ratings_parquet, movies_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97a4740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet paths:\n",
      "..\\data\\100K\\ratings.parquet\n",
      "..\\data\\Full33M\\ratings.parquet\n",
      "..\\data\\Full33M\\movies.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036ade99b3a548f6866a2da8ae93b305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV -> Parquet conversion finished.\n"
     ]
    }
   ],
   "source": [
    "# === CONVERSÃO CSV -> PARQUET  ===\n",
    "\n",
    "ratings_100k_parquet = ratings_100k.with_suffix(\".parquet\")\n",
    "ratings_33m_parquet  = ratings_33m.with_suffix(\".parquet\")\n",
    "movies_33m_parquet   = movies_33m.with_suffix(\".parquet\")\n",
    "\n",
    "print(\"Parquet paths:\")\n",
    "print(ratings_100k_parquet)\n",
    "print(ratings_33m_parquet)\n",
    "print(movies_33m_parquet)\n",
    "\n",
    "# Converter \n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_100k_csv}'))\n",
    "TO '{ratings_100k_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_33m_csv}'))\n",
    "TO '{ratings_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{movies_33m_csv}'))\n",
    "TO '{movies_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "print(\"CSV -> Parquet conversion finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8dfd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função medir_tempo\n",
    "\n",
    "def medir_tempo(query):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(query).df()\n",
    "    return round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaf437",
   "metadata": {},
   "source": [
    "### 1.3 Benchmark 1 — CSV vs Parquet Performance (AVG ratings + GROUP BY moviesId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ebe3",
   "metadata": {},
   "source": [
    "We measure the execution time of a simple aggregation query (AVG(rating) GROUP BY movieId)\n",
    "executed using DuckDB, running on both CSV and Parquet files for the MovieLens 100k\n",
    "and 33M datasets. This benchmark isolates the impact of the storage format on query\n",
    "performance within DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9e9623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CSV_100k': 0.066,\n",
       " 'PARQUET_100k': 0.015,\n",
       " 'CSV_33M': 1.885,\n",
       " 'PARQUET_33M': 0.159}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medições CSV vs Parquet\n",
    "\n",
    "tempos = {\n",
    "    \"CSV_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k_csv}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k_parquet}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"CSV_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m_csv}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m_parquet}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "}\n",
    "\n",
    "tempos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a067f54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>CSV time (s)</th>\n",
       "      <th>Parquet time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33M</td>\n",
       "      <td>1.885</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  CSV time (s)  Parquet time (s)\n",
       "0    100k         0.066             0.015\n",
       "1     33M         1.885             0.159"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela comparativa\n",
    "\n",
    "df_tempo = pd.DataFrame([\n",
    "    [\"100k\", tempos[\"CSV_100k\"], tempos[\"PARQUET_100k\"]],\n",
    "    [\"33M\", tempos[\"CSV_33M\"], tempos[\"PARQUET_33M\"]],\n",
    "], columns=[\"Dataset\", \"CSV time (s)\", \"Parquet time (s)\"])\n",
    "\n",
    "df_tempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c46e60",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "This benchmark measures the execution time of a simple aggregation query (`AVG(rating)` grouped by `movieId`) across four scenarios:\n",
    "\n",
    "- CSV 100K\n",
    "- Parquet 100K\n",
    "- CSV 33M\n",
    "- Parquet 33M\n",
    "\n",
    "The results show the strong impact of storage format on query speed, with Parquet providing substantial improvements—especially at larger scales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0717edf6",
   "metadata": {},
   "source": [
    "__Close the connection (when done)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da0104a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con.close()\n",
    "#print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4aa39",
   "metadata": {},
   "source": [
    "## 2.0 DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d6dc5",
   "metadata": {},
   "source": [
    "### 2.1 Benchmark 2 — Simple COUNT() Query (DuckDB vs Polars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda6b7a",
   "metadata": {},
   "source": [
    "Here we run the same aggregation query (`AVG(rating)` grouped by `movieId`) on Parquet files using DuckDB and Polars, for 100k and 33M rows, in order to compare the execution engines under a simple workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97aa5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths para Parquet\n",
    "\n",
    "p100k = ratings_100k.with_suffix(\".parquet\")\n",
    "p33m = ratings_33m.with_suffix(\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9274a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de benchmark\n",
    "\n",
    "def run_duckdb(path):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{path}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\").df()\n",
    "    return round(time.time() - t0, 3)\n",
    "\n",
    "def run_polars(path):\n",
    "    t0 = time.time()\n",
    "    (\n",
    "        pl.scan_parquet(str(path))     \n",
    "          .group_by(\"movieId\")         \n",
    "          .agg(pl.col(\"rating\").mean())\n",
    "          .collect()\n",
    "    )\n",
    "    return round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9e96088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33m</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  DuckDB (s)  Polars (s)\n",
       "0    100k       0.006       0.026\n",
       "1     33m       0.151       0.716"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparação\n",
    "\n",
    "df_duck_polars = pd.DataFrame([\n",
    "    [\"100k\", run_duckdb(p100k), run_polars(p100k)],\n",
    "    [\"33m\", run_duckdb(p33m), run_polars(p33m)],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_duck_polars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39228",
   "metadata": {},
   "source": [
    "### 2.2 Benchmark 3 — Aggregation + JOIN (AVG, COUNT, STDDEV) — DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707409",
   "metadata": {},
   "source": [
    "This benchmark uses a more realistic analytical workload on the 33M dataset:\n",
    "we compute average rating, number of ratings and standard deviation per movie, join with the movies table to retrieve titles, filter movies with at least 500 ratings, and sort by total_ratings (TOP 100). The goal is to compare DuckDB and Polars under a heavier analytical query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb8192f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RATINGS = 500\n",
    "\n",
    "def run_duckdb_movie_stats(con):\n",
    "    sql = f\"\"\"\n",
    "    WITH movie_stats AS (\n",
    "        SELECT\n",
    "            m.movieId,\n",
    "            m.title,\n",
    "            AVG(r.rating) AS avg_rating,\n",
    "            COUNT(*) AS total_ratings,\n",
    "            STDDEV_POP(r.rating) AS std_rating\n",
    "        FROM ratings_33m_parquet r\n",
    "        JOIN movies_33m_parquet m USING (movieId)\n",
    "        GROUP BY m.movieId, m.title\n",
    "        HAVING COUNT(*) >= {MIN_RATINGS}\n",
    "    )\n",
    "    SELECT\n",
    "        movieId,\n",
    "        title,\n",
    "        ROUND(avg_rating, 3)  AS avg_rating,\n",
    "        total_ratings,\n",
    "        ROUND(std_rating, 3)  AS std_rating\n",
    "    FROM movie_stats\n",
    "    ORDER BY total_ratings DESC\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    return con.sql(sql).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14668867",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "\n",
    "#df_duckdb_stats.head(), t_duckdb_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05aa519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "\n",
    "#df_duckdb_stats.head(), t_duckdb_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5b521fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4fddad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_polars_movie_stats_33m():\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # usar os ficheiros PARQUET, não os CSV\n",
    "    ratings = (\n",
    "        pl.scan_parquet(str(ratings_33m_parquet))\n",
    "        .select([\"movieId\", \"rating\"])\n",
    "    )\n",
    "\n",
    "    movies  = (\n",
    "        pl.scan_parquet(str(movies_33m_parquet))\n",
    "        .select([\"movieId\", \"title\"])\n",
    "    )\n",
    "\n",
    "    MIN_RATINGS = 500\n",
    "\n",
    "    result = (\n",
    "        ratings\n",
    "        .group_by(\"movieId\")\n",
    "        .agg([\n",
    "            pl.col(\"rating\").mean().alias(\"avg_rating\"),\n",
    "            pl.count().alias(\"total_ratings\"),\n",
    "            pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "        ])\n",
    "        .filter(pl.col(\"total_ratings\") >= MIN_RATINGS)\n",
    "        .join(movies, on=\"movieId\")\n",
    "        .select([\n",
    "            \"movieId\",\n",
    "            \"title\",\n",
    "            pl.col(\"avg_rating\").round(3),\n",
    "            \"total_ratings\",\n",
    "            pl.col(\"std_rating\").round(3),\n",
    "        ])\n",
    "        .sort(\"total_ratings\", descending=True)\n",
    "        .limit(100)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return result, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c97ab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars_stats_33m, t_polars_stats_33m = run_polars_movie_stats_33m()\n",
    "#df_polars_stats_33m.head(), t_polars_stats_33m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc776f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33M (complex)</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>0.676009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset  DuckDB (s)  Polars (s)\n",
       "0  33M (complex)    0.999457    0.676009"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complex = pd.DataFrame([\n",
    "    [\"33M (complex)\", t_duckdb_stats, t_polars_stats_33m],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_complex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f4e21",
   "metadata": {},
   "source": [
    "### 2.3 Benchmark 3 - further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300ddfc",
   "metadata": {},
   "source": [
    "Benchmark 3 evaluates a heavier analytical workload: computing movie-level statistics (AVG, COUNT, STD) over the full 33M ratings and joining the result with the movies table. The filter MIN_RATINGS ≥ 500 reduces the dataset, but changing this threshold alters how many rows and movies are processed.\n",
    "\n",
    "This subsection explores how the result size changes when we adjust the filter (e.g., 500 → 50) to better understand how much data each engine needs to aggregate. This helps explain performance differences by linking execution time to the actual amount of work performed.\n",
    "\n",
    "We return only the TOP 100 movies because benchmark 3 is focused on measuring the heavy part of the query (aggregation + filtering + join) rather than the size of the final output. Limiting the results ensures fair comparison between engines and aligns with common analytical patterns where large datasets are reduced to a small ranked output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad590ef",
   "metadata": {},
   "source": [
    "**DuckDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7011364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_duckdb_movie_stats(con, min_ratings=500):\n",
    "    sql = f\"\"\"\n",
    "    WITH movie_stats AS (\n",
    "        SELECT\n",
    "            m.movieId,\n",
    "            m.title,\n",
    "            AVG(r.rating) AS avg_rating,\n",
    "            COUNT(*) AS total_ratings,\n",
    "            STDDEV_POP(r.rating) AS std_rating\n",
    "        FROM ratings_33m_parquet r\n",
    "        JOIN movies_33m_parquet m USING (movieId)\n",
    "        GROUP BY m.movieId, m.title\n",
    "        HAVING COUNT(*) >= {min_ratings}\n",
    "    )\n",
    "    SELECT\n",
    "        movieId,\n",
    "        title,\n",
    "        ROUND(avg_rating, 3) AS avg_rating,\n",
    "        total_ratings,\n",
    "        ROUND(std_rating, 3) AS std_rating\n",
    "    FROM movie_stats\n",
    "    ORDER BY total_ratings DESC\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    return con.sql(sql).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "304958f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ratings = 50 -> 100 movies\n",
      "min_ratings = 100 -> 100 movies\n",
      "min_ratings = 500 -> 100 movies\n"
     ]
    }
   ],
   "source": [
    "for thr in [50, 100, 500]:\n",
    "    df_tmp = run_duckdb_movie_stats(con, min_ratings=thr)\n",
    "    print(f\"min_ratings = {thr} -> {len(df_tmp)} movies\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274b3b3",
   "metadata": {},
   "source": [
    "**Polars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c280bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_polars_movie_stats_33m(min_ratings=500):\n",
    "    ratings = (\n",
    "        pl.scan_parquet(str(ratings_33m_parquet))\n",
    "        .select([\"movieId\", \"rating\"])\n",
    "    )\n",
    "\n",
    "    movies = (\n",
    "        pl.scan_parquet(str(movies_33m_parquet))\n",
    "        .select([\"movieId\", \"title\"])\n",
    "    )\n",
    "\n",
    "    result = (\n",
    "        ratings\n",
    "        .group_by(\"movieId\")\n",
    "        .agg([\n",
    "            pl.col(\"rating\").mean().alias(\"avg_rating\"),\n",
    "            pl.count().alias(\"total_ratings\"),\n",
    "            pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "        ])\n",
    "        .filter(pl.col(\"total_ratings\") >= min_ratings)\n",
    "        .join(movies, on=\"movieId\")\n",
    "        .select([\n",
    "            \"movieId\",\n",
    "            \"title\",\n",
    "            pl.col(\"avg_rating\").round(3),\n",
    "            \"total_ratings\",\n",
    "            pl.col(\"std_rating\").round(3),\n",
    "        ])\n",
    "        .sort(\"total_ratings\", descending=True)\n",
    "        .limit(100)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return result, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efd32bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarac\\AppData\\Local\\Temp\\ipykernel_12452\\3283391236.py:17: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"total_ratings\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ratings = 500 -> 100 movies, 5589898 ratings in subset\n"
     ]
    }
   ],
   "source": [
    "df_polars_stats_33m, t_polars_stats_33m = run_polars_movie_stats_33m(min_ratings=500)\n",
    "\n",
    "n_movies = df_polars_stats_33m.height\n",
    "total_ratings_subset = df_polars_stats_33m[\"total_ratings\"].sum()\n",
    "\n",
    "print(f\"min_ratings = 500 -> {n_movies} movies, {total_ratings_subset} ratings in subset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38c61cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarac\\AppData\\Local\\Temp\\ipykernel_12452\\3283391236.py:17: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"total_ratings\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ratings =  50 ->  100 movies, sum(total_ratings) = 5589898\n",
      "min_ratings = 100 ->  100 movies, sum(total_ratings) = 5589898\n",
      "min_ratings = 500 ->  100 movies, sum(total_ratings) = 5589898\n"
     ]
    }
   ],
   "source": [
    "for thr in [50, 100, 500]:\n",
    "    df_tmp, t_tmp = run_polars_movie_stats_33m(min_ratings=thr)\n",
    "    print(\n",
    "        f\"min_ratings = {thr:3d} -> \"\n",
    "        f\"{df_tmp.height:4d} movies, \"\n",
    "        f\"sum(total_ratings) = {int(df_tmp['total_ratings'].sum())}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcab8e",
   "metadata": {},
   "source": [
    "**FALTA A CONCLUSÃO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90d778",
   "metadata": {},
   "source": [
    "## 3.0 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33b948fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmark 1 - 100k (CSV vs Parquet)</td>\n",
       "      <td>DuckDB CSV</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benchmark 1 - 100k (CSV vs Parquet)</td>\n",
       "      <td>DuckDB Parquet</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benchmark 1 - 33M (CSV vs Parquet)</td>\n",
       "      <td>DuckDB CSV</td>\n",
       "      <td>1.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmark 1 - 33M (CSV vs Parquet)</td>\n",
       "      <td>DuckDB Parquet</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benchmark 2 - 100k (simple)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Benchmark 2 - 100k (simple)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Benchmark 2 - 33M (simple)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benchmark 2 - 33M (simple)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Benchmark 3 - 33M (complex)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.999457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Benchmark 3 - 33M (complex)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.676009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Scenario          Engine  Time (s)\n",
       "0  Benchmark 1 - 100k (CSV vs Parquet)      DuckDB CSV  0.066000\n",
       "1  Benchmark 1 - 100k (CSV vs Parquet)  DuckDB Parquet  0.015000\n",
       "2   Benchmark 1 - 33M (CSV vs Parquet)      DuckDB CSV  1.885000\n",
       "3   Benchmark 1 - 33M (CSV vs Parquet)  DuckDB Parquet  0.159000\n",
       "4          Benchmark 2 - 100k (simple)          DuckDB  0.006000\n",
       "5          Benchmark 2 - 100k (simple)          Polars  0.026000\n",
       "6           Benchmark 2 - 33M (simple)          DuckDB  0.151000\n",
       "7           Benchmark 2 - 33M (simple)          Polars  0.716000\n",
       "8          Benchmark 3 - 33M (complex)          DuckDB  0.999457\n",
       "9          Benchmark 3 - 33M (complex)          Polars  0.676009"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.DataFrame([\n",
    "    [\"Benchmark 1 - 100k (CSV vs Parquet)\", \"DuckDB CSV\", tempos[\"CSV_100k\"]],\n",
    "    [\"Benchmark 1 - 100k (CSV vs Parquet)\", \"DuckDB Parquet\", tempos[\"PARQUET_100k\"]],\n",
    "    [\"Benchmark 1 - 33M (CSV vs Parquet)\", \"DuckDB CSV\", tempos[\"CSV_33M\"]],\n",
    "    [\"Benchmark 1 - 33M (CSV vs Parquet)\", \"DuckDB Parquet\", tempos[\"PARQUET_33M\"]],\n",
    "    [\"Benchmark 2 - 100k (simple)\", \"DuckDB\", df_duck_polars.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 2 - 100k (simple)\", \"Polars\", df_duck_polars.loc[0, \"Polars (s)\"]],\n",
    "    [\"Benchmark 2 - 33M (simple)\", \"DuckDB\", df_duck_polars.loc[1, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 2 - 33M (simple)\", \"Polars\", df_duck_polars.loc[1, \"Polars (s)\"]],\n",
    "    [\"Benchmark 3 - 33M (complex)\", \"DuckDB\", df_complex.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 3 - 33M (complex)\", \"Polars\", df_complex.loc[0, \"Polars (s)\"]],\n",
    "], columns=[\"Scenario\", \"Engine\", \"Time (s)\"])\n",
    "\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352502a",
   "metadata": {},
   "source": [
    "The results show that Parquet is substantially faster than CSV, delivering up to a considerable improvement on the 33M dataset.\n",
    "\n",
    "In the engine comparison (Benchmark 2), DuckDB is faster on simple aggregations—especially on smaller datasets—while Polars remains competitive.\n",
    "\n",
    "In the complex analytical query (Benchmark 3), Polars outperforms DuckDB (0.67s vs 1.02s), demonstrating better scalability under heavier workloads.\n",
    "\n",
    "Both engines achieve sub-second performance on 33M rows when using Parquet, highlighting the efficiency of columnar storage.\n",
    "\n",
    "Overall, Parquet + Polars provides the strongest performance for large-scale analytical queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
