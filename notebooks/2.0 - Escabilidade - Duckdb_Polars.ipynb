{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d086af0",
   "metadata": {},
   "source": [
    "### 1 Introduction\n",
    "\n",
    "**CSV vs PARQUET (Arrow)**\n",
    "- escalabilidade do formato\n",
    "- usando DuckDB local\n",
    "- com MovieLens 100k e 33M\n",
    "\n",
    "#### 2 Library import, Data and files import, duckdb import and conversion of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5cd968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths defined successfully.\n",
      "DuckDB connection opened.\n"
     ]
    }
   ],
   "source": [
    "#   BLOCO INICIAL — IMPORTS & PATHS & SETUP\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# === PATHS FOR THE DATASETS ===\n",
    "\n",
    "## MovieLens 100k\n",
    "DATA_100k = Path(\"..\") / \"data\" / \"100K\"\n",
    "ratings_100k_csv = DATA_100k / \"ratings.csv\"\n",
    "movies_100k_csv  = DATA_100k / \"movies.csv\"\n",
    "tags_100k_csv    = DATA_100k / \"tags.csv\"\n",
    "links_100k_csv   = DATA_100k / \"links.csv\"\n",
    "\n",
    "## MovieLens 33M\n",
    "DATA_33m = Path(\"..\") / \"data\" / \"Full33M\"\n",
    "ratings_33m_csv = DATA_33m / \"ratings.csv\"\n",
    "movies_33m_csv  = DATA_33m / \"movies.csv\"\n",
    "tags_33m_csv    = DATA_33m / \"tags.csv\"\n",
    "links_33m_csv   = DATA_33m / \"links.csv\"\n",
    "\n",
    "print(\"Paths defined successfully.\")\n",
    "\n",
    "# === Local DuckDB connection ===\n",
    "con = duckdb.connect(\"movielens_local.duckdb\")\n",
    "print(\"DuckDB connection opened.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ceffa",
   "metadata": {},
   "source": [
    "### 1.2 Create Parquet Tables in DuckDB (ratings_parquet, movies_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26294597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet paths:\n",
      "..\\data\\100K\\ratings.parquet\n",
      "..\\data\\Full33M\\ratings.parquet\n",
      "..\\data\\Full33M\\movies.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb1374f2cbf4d5d947f11966bda87f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV -> Parquet conversion finished.\n"
     ]
    }
   ],
   "source": [
    "# === CONVERSÃO CSV -> PARQUET  ===\n",
    "\n",
    "ratings_100k_parquet = ratings_100k.with_suffix(\".parquet\")\n",
    "ratings_33m_parquet  = ratings_33m.with_suffix(\".parquet\")\n",
    "movies_33m_parquet   = movies_33m.with_suffix(\".parquet\")\n",
    "\n",
    "print(\"Parquet paths:\")\n",
    "print(ratings_100k_parquet)\n",
    "print(ratings_33m_parquet)\n",
    "print(movies_33m_parquet)\n",
    "\n",
    "# Converter \n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_100k_csv}'))\n",
    "TO '{ratings_100k_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_33m_csv}'))\n",
    "TO '{ratings_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{movies_33m_csv}'))\n",
    "TO '{movies_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "print(\"CSV -> Parquet conversion finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fbb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ratings_parquet</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tags_parquet</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        table_name  table_type\n",
       "0  ratings_parquet  BASE TABLE\n",
       "1     tags_parquet  BASE TABLE"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all tables in the database\n",
    "con.sql(\"\"\"\n",
    "SELECT table_name, table_type\n",
    "FROM information_schema.tables\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35af9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\100K\\ratings.csv\n",
      "..\\data\\Full33M\\ratings.csv\n"
     ]
    }
   ],
   "source": [
    "print(ratings_100k_csv)\n",
    "print(ratings_33m_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9bc542",
   "metadata": {},
   "source": [
    "#### 3 Performance test and measuremnts\n",
    "##### 3.1 Sub to measure time on queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8dfd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função medir_tempo\n",
    "\n",
    "def medir_tempo(query):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(query).df()\n",
    "    return round(time.time() - t0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf764bb0",
   "metadata": {},
   "source": [
    "##### 3.2 Test with simple Query in file with movieId: csv 100k vs parque 100k and csv with 33M vs parquet with 33M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaf437",
   "metadata": {},
   "source": [
    "### 1.3 Benchmark 1 — CSV vs Parquet Performance (AVG ratings + GROUP BY moviesId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ebe3",
   "metadata": {},
   "source": [
    "We measure the execution time of a simple aggregation query (AVG(rating) GROUP BY movieId)\n",
    "executed using DuckDB, running on both CSV and Parquet files for the MovieLens 100k\n",
    "and 33M datasets. This benchmark isolates the impact of the storage format on query\n",
    "performance within DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9e9623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CSV_100k': 0.065,\n",
       " 'PARQUET_100k': 0.014,\n",
       " 'CSV_33M': 1.045,\n",
       " 'PARQUET_33M': 0.184}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medições CSV vs Parquet\n",
    "\n",
    "tempos = {\n",
    "    \"CSV_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k_csv}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k_parquet}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"CSV_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m_csv}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m_parquet}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "}\n",
    "\n",
    "tempos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a067f54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>CSV time (s)</th>\n",
       "      <th>Parquet time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33M</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Tempo CSV (s)  Tempo Parquet (s)\n",
       "0    100k          0.065              0.014\n",
       "1     33M          1.045              0.184"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela comparativa\n",
    "\n",
    "df_tempo = pd.DataFrame([\n",
    "    [\"100k\", tempos[\"CSV_100k\"], tempos[\"PARQUET_100k\"]],\n",
    "    [\"33M\", tempos[\"CSV_33M\"], tempos[\"PARQUET_33M\"]],\n",
    "], columns=[\"Dataset\", \"CSV time (s)\", \"Parquet time (s)\"])\n",
    "\n",
    "df_tempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c46e60",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "This benchmark measures the execution time of a simple aggregation query (`AVG(rating)` grouped by `movieId`) across four scenarios:\n",
    "\n",
    "- CSV 100K\n",
    "- Parquet 100K\n",
    "- CSV 33M\n",
    "- Parquet 33M\n",
    "\n",
    "The results show the strong impact of storage format on query speed, with Parquet providing substantial improvements—especially at larger scales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0717edf6",
   "metadata": {},
   "source": [
    "__Close the connection (when done)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da0104a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con.close()\n",
    "#print(\"Connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4aa39",
   "metadata": {},
   "source": [
    "## 2.0 DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d6dc5",
   "metadata": {},
   "source": [
    "### 2.1 Benchmark 2 — Simple COUNT() Query (DuckDB vs Polars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda6b7a",
   "metadata": {},
   "source": [
    "Here we run the same aggregation query (`AVG(rating)` grouped by `movieId`) on Parquet files using DuckDB and Polars, for 100k and 33M rows, in order to compare the execution engines under a simple workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths para Parquet\n",
    "\n",
    "p100k = ratings_100k.with_suffix(\".parquet\")\n",
    "p33m = ratings_33m.with_suffix(\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de benchmark\n",
    "\n",
    "def run_duckdb(path):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{path}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\").df()\n",
    "    return round(time.time() - t0, 3)\n",
    "\n",
    "def run_polars(path):\n",
    "    t0 = time.time()\n",
    "    (\n",
    "        pl.scan_parquet(str(path))     \n",
    "          .group_by(\"movieId\")         \n",
    "          .agg(pl.col(\"rating\").mean())\n",
    "          .collect()\n",
    "    )\n",
    "    return round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e96088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33m</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  DuckDB (s)  Polars (s)\n",
       "0    100k       0.006       0.026\n",
       "1     33m       0.151       0.716"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparação\n",
    "\n",
    "df_duck_polars = pd.DataFrame([\n",
    "    [\"100k\", run_duckdb(p100k), run_polars(p100k)],\n",
    "    [\"33m\", run_duckdb(p33m), run_polars(p33m)],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_duck_polars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39228",
   "metadata": {},
   "source": [
    "### 2.2 Benchmark 3 — Aggregation + JOIN (AVG, COUNT, STDDEV) — DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707409",
   "metadata": {},
   "source": [
    "This benchmark uses a more realistic analytical workload on the 33M dataset:\n",
    "we compute average rating, number of ratings and standard deviation per movie, join with the movies table to retrieve titles, filter movies with at least 500 ratings, and sort by total_ratings (TOP 100). The goal is to compare DuckDB and Polars under a heavier analytical query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f87774",
   "metadata": {},
   "source": [
    "**DuckDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8192f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MIN_RATINGS = 500\n",
    "\n",
    "def run_duckdb_movie_stats(con):\n",
    "    sql = f\"\"\"\n",
    "    WITH movie_stats AS (\n",
    "        SELECT\n",
    "            m.movieId,\n",
    "            m.title,\n",
    "            AVG(r.rating) AS avg_rating,\n",
    "            COUNT(*) AS total_ratings,\n",
    "            STDDEV_POP(r.rating) AS std_rating\n",
    "        FROM ratings_33m_parquet r\n",
    "        JOIN movies_33m_parquet m USING (movieId)\n",
    "        GROUP BY m.movieId, m.title\n",
    "        HAVING COUNT(*) >= {MIN_RATINGS}\n",
    "    )\n",
    "    SELECT\n",
    "        movieId,\n",
    "        title,\n",
    "        ROUND(avg_rating, 3)  AS avg_rating,\n",
    "        total_ratings,\n",
    "        ROUND(std_rating, 3)  AS std_rating\n",
    "    FROM movie_stats\n",
    "    ORDER BY total_ratings DESC\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    return con.sql(sql).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14668867",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "\n",
    "#df_duckdb_stats.head(), t_duckdb_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05aa519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "\n",
    "#df_duckdb_stats.head(), t_duckdb_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad84db",
   "metadata": {},
   "source": [
    "**Polars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fddad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_polars_movie_stats_33m():\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # usar os ficheiros PARQUET, não os CSV\n",
    "    ratings = (\n",
    "        pl.scan_parquet(str(ratings_33m_parquet))\n",
    "        .select([\"movieId\", \"rating\"])\n",
    "    )\n",
    "\n",
    "    movies  = (\n",
    "        pl.scan_parquet(str(movies_33m_parquet))\n",
    "        .select([\"movieId\", \"title\"])\n",
    "    )\n",
    "\n",
    "    MIN_RATINGS = 500\n",
    "\n",
    "    result = (\n",
    "        ratings\n",
    "        .group_by(\"movieId\")\n",
    "        .agg([\n",
    "            pl.col(\"rating\").mean().alias(\"avg_rating\"),\n",
    "            pl.count().alias(\"total_ratings\"),\n",
    "            pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "        ])\n",
    "        .filter(pl.col(\"total_ratings\") >= MIN_RATINGS)\n",
    "        .join(movies, on=\"movieId\")\n",
    "        .select([\n",
    "            \"movieId\",\n",
    "            \"title\",\n",
    "            pl.col(\"avg_rating\").round(3),\n",
    "            \"total_ratings\",\n",
    "            pl.col(\"std_rating\").round(3),\n",
    "        ])\n",
    "        .sort(\"total_ratings\", descending=True)\n",
    "        .limit(100)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return result, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c97ab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_polars_stats_33m, t_polars_stats_33m = run_polars_movie_stats_33m()\n",
    "#df_polars_stats_33m.head(), t_polars_stats_33m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc776f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33M (complex)</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>0.676009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset  DuckDB (s)  Polars (s)\n",
       "0  33M (complex)    0.999457    0.676009"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complex = pd.DataFrame([\n",
    "    [\"33M (complex)\", t_duckdb_stats, t_polars_stats_33m],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_complex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90d778",
   "metadata": {},
   "source": [
    "## 3.0 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33b948fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmark 1 - 100k (CSV vs Parquet)</td>\n",
       "      <td>DuckDB CSV</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benchmark 1 - 100k (CSV vs Parquet)</td>\n",
       "      <td>DuckDB Parquet</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benchmark 1 - 33M (CSV vs Parquet)</td>\n",
       "      <td>DuckDB CSV</td>\n",
       "      <td>1.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmark 1 - 33M (CSV vs Parquet)</td>\n",
       "      <td>DuckDB Parquet</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benchmark 2 - 100k (simple)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Benchmark 2 - 100k (simple)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Benchmark 2 - 33M (simple)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benchmark 2 - 33M (simple)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Benchmark 3 - 33M (complex)</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.999457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Benchmark 3 - 33M (complex)</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.676009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Scenario          Engine  Time (s)\n",
       "0  Benchmark 1 - 100k (CSV vs Parquet)      DuckDB CSV  0.066000\n",
       "1  Benchmark 1 - 100k (CSV vs Parquet)  DuckDB Parquet  0.015000\n",
       "2   Benchmark 1 - 33M (CSV vs Parquet)      DuckDB CSV  1.885000\n",
       "3   Benchmark 1 - 33M (CSV vs Parquet)  DuckDB Parquet  0.159000\n",
       "4          Benchmark 2 - 100k (simple)          DuckDB  0.006000\n",
       "5          Benchmark 2 - 100k (simple)          Polars  0.026000\n",
       "6           Benchmark 2 - 33M (simple)          DuckDB  0.151000\n",
       "7           Benchmark 2 - 33M (simple)          Polars  0.716000\n",
       "8          Benchmark 3 - 33M (complex)          DuckDB  0.999457\n",
       "9          Benchmark 3 - 33M (complex)          Polars  0.676009"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.DataFrame([\n",
    "    [\"Benchmark 1 - 100k (CSV vs Parquet)\", \"DuckDB CSV\", tempos[\"CSV_100k\"]],\n",
    "    [\"Benchmark 1 - 100k (CSV vs Parquet)\", \"DuckDB Parquet\", tempos[\"PARQUET_100k\"]],\n",
    "    [\"Benchmark 1 - 33M (CSV vs Parquet)\", \"DuckDB CSV\", tempos[\"CSV_33M\"]],\n",
    "    [\"Benchmark 1 - 33M (CSV vs Parquet)\", \"DuckDB Parquet\", tempos[\"PARQUET_33M\"]],\n",
    "    [\"Benchmark 2 - 100k (simple)\", \"DuckDB\", df_duck_polars.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 2 - 100k (simple)\", \"Polars\", df_duck_polars.loc[0, \"Polars (s)\"]],\n",
    "    [\"Benchmark 2 - 33M (simple)\", \"DuckDB\", df_duck_polars.loc[1, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 2 - 33M (simple)\", \"Polars\", df_duck_polars.loc[1, \"Polars (s)\"]],\n",
    "    [\"Benchmark 3 - 33M (complex)\", \"DuckDB\", df_complex.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"Benchmark 3 - 33M (complex)\", \"Polars\", df_complex.loc[0, \"Polars (s)\"]],\n",
    "], columns=[\"Scenario\", \"Engine\", \"Time (s)\"])\n",
    "\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352502a",
   "metadata": {},
   "source": [
    "The results show that Parquet is substantially faster than CSV, delivering up to a considerable improvement on the 33M dataset.\n",
    "\n",
    "In the engine comparison (Benchmark 2), DuckDB is faster on simple aggregations—especially on smaller datasets—while Polars remains competitive.\n",
    "\n",
    "In the complex analytical query (Benchmark 3), Polars outperforms DuckDB (0.67s vs 1.02s), demonstrating better scalability under heavier workloads.\n",
    "\n",
    "Both engines achieve sub-second performance on 33M rows when using Parquet, highlighting the efficiency of columnar storage.\n",
    "\n",
    "Overall, Parquet + Polars provides the strongest performance for large-scale analytical queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
