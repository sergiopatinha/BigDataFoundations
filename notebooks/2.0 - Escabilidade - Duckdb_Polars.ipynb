{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d086af0",
   "metadata": {},
   "source": [
    "# 1 Introduction\n",
    "\n",
    "This notebook explores the scalability and performance characteristics of working with large analytical datasets using modern data formats and processing engines. Focusing on **CSV** versus **Parquet (Arrow)** formats, it demonstrates how efficient storage layouts—combined with high-performance local query engines such as **DuckDB** and fast DataFrame libraries like **Polars** can significantly improve query speed, memory usage, and overall workflow efficiency.\n",
    "\n",
    "To structure this exploration, we will:\n",
    "\n",
    "- Load the MovieLens datasets in their original **CSV** format\n",
    "\n",
    "- Convert the datasets into the **Parquet (Arrow)** format to benefit from columnar storage.\n",
    "\n",
    "- Create and query **Parquet**-backed tables in **DuckDB**.\n",
    "\n",
    "- Execute benchmark tests using both **DuckDB** and **Polars** across multiple scenarios.\n",
    "\n",
    "- Compare performance metrics as dataset size and query complexity increase.\n",
    "\n",
    "Through these steps, we aim to highlight how modern columnar formats and vectorized engines scale under more demanding analytical workloads. In particular, we expect **Polars** and **Parquet** to deliver increasingly superior performance—both in execution time and resource efficiency as data volume grows and queries become more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675df8a",
   "metadata": {},
   "source": [
    "# 2 Library import, Data and files import, duckdb import and conversion of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5cd968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths defined successfully.\n",
      "DuckDB connection opened.\n"
     ]
    }
   ],
   "source": [
    "#   BLOCO INICIAL — IMPORTS & PATHS & SETUP\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# === PATHS FOR THE DATASETS ===\n",
    "\n",
    "## MovieLens 100k\n",
    "DATA_100k = Path(\"..\") / \"data\" / \"100k\"\n",
    "ratings_100k_csv = DATA_100k / \"ratings.csv\"\n",
    "movies_100k_csv  = DATA_100k / \"movies.csv\"\n",
    "tags_100k_csv    = DATA_100k / \"tags.csv\"\n",
    "links_100k_csv   = DATA_100k / \"links.csv\"\n",
    "\n",
    "## MovieLens 33M\n",
    "DATA_33m = Path(\"..\") / \"data\" / \"Full33M\"\n",
    "ratings_33m_csv = DATA_33m / \"ratings.csv\"\n",
    "movies_33m_csv  = DATA_33m / \"movies.csv\"\n",
    "tags_33m_csv    = DATA_33m / \"tags.csv\"\n",
    "links_33m_csv   = DATA_33m / \"links.csv\"\n",
    "\n",
    "print(\"Paths defined successfully.\")\n",
    "\n",
    "# === Local DuckDB connection ===\n",
    "con = duckdb.connect(\"movielens_local.duckdb\")\n",
    "print(\"DuckDB connection opened.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ceffa",
   "metadata": {},
   "source": [
    "### 1.2 Create Parquet Tables in DuckDB (ratings_parquet, movies_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26294597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet paths:\n",
      "..\\data\\100k\\ratings.parquet\n",
      "..\\data\\Full33M\\ratings.parquet\n",
      "..\\data\\Full33M\\movies.parquet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eb559baf92434fb2e39c53377bc580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV -> Parquet conversion finished.\n"
     ]
    }
   ],
   "source": [
    "# === CONVERSÃO CSV -> PARQUET  ===\n",
    "\n",
    "ratings_100k_parquet = ratings_100k_csv.with_suffix(\".parquet\")\n",
    "ratings_33m_parquet  = ratings_33m_csv.with_suffix(\".parquet\")\n",
    "movies_33m_parquet   = movies_33m_csv.with_suffix(\".parquet\")\n",
    "\n",
    "print(\"Parquet paths:\")\n",
    "print(ratings_100k_parquet)\n",
    "print(ratings_33m_parquet)\n",
    "print(movies_33m_parquet)\n",
    "\n",
    "# Converter \n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_100k_csv}'))\n",
    "TO '{ratings_100k_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{ratings_33m_csv}'))\n",
    "TO '{ratings_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "duckdb.sql(f\"\"\"\n",
    "COPY (SELECT * FROM read_csv_auto('{movies_33m_csv}'))\n",
    "TO '{movies_33m_parquet}'\n",
    "(FORMAT PARQUET);\n",
    "\"\"\")\n",
    "\n",
    "print(\"CSV -> Parquet conversion finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59fbb58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [table_name, table_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all tables in the database\n",
    "con.sql(\"\"\"\n",
    "SELECT table_name, table_type\n",
    "FROM information_schema.tables\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35af9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\100k\\ratings.csv\n",
      "..\\data\\Full33M\\ratings.csv\n"
     ]
    }
   ],
   "source": [
    "print(ratings_100k_csv)\n",
    "print(ratings_33m_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9bc542",
   "metadata": {},
   "source": [
    "# 3 Performance test and measuremnts\n",
    "## 3.1 Fuction to measure time on queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8dfd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função medir_tempo\n",
    "\n",
    "def medir_tempo(query):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(query).df()\n",
    "    return round(time.time() - t0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf764bb0",
   "metadata": {},
   "source": [
    "## 3.2 Test with simple Query in file with movieId: CSV 100k vs PARQUET 100k and CSV with 33M vs PARQUET with 33M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaf437",
   "metadata": {},
   "source": [
    "### Benchmark 1 — CSV vs Parquet Performance (AVG ratings + GROUP BY moviesId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060ebe3",
   "metadata": {},
   "source": [
    "We measure the execution time of a simple aggregation query (AVG(rating) GROUP BY movieId) executed using DuckDB, running on both CSV and Parquet files for the MovieLens 100k and 33M datasets. This benchmark isolates the impact of the storage format on query performance within DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e9623b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9996476357ee4a7497cf194f0659a361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'CSV_100k': 0.764,\n",
       " 'PARQUET_100k': 0.101,\n",
       " 'CSV_33M': 7.435,\n",
       " 'PARQUET_33M': 0.89}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medições CSV vs Parquet\n",
    "\n",
    "tempos = {\n",
    "    \"CSV_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k_csv}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_100k\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_100k_parquet}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"CSV_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m_csv}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "\n",
    "    \"PARQUET_33M\": medir_tempo(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{ratings_33m_parquet}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\"),\n",
    "}\n",
    "\n",
    "tempos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a067f54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>CSV time (s)</th>\n",
       "      <th>Parquet time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33M</td>\n",
       "      <td>7.435</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  CSV time (s)  Parquet time (s)\n",
       "0    100k         0.764             0.101\n",
       "1     33M         7.435             0.890"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela comparativa\n",
    "\n",
    "df_tempo = pd.DataFrame([\n",
    "    [\"100k\", tempos[\"CSV_100k\"], tempos[\"PARQUET_100k\"]],\n",
    "    [\"33M\", tempos[\"CSV_33M\"], tempos[\"PARQUET_33M\"]],\n",
    "], columns=[\"Dataset\", \"CSV time (s)\", \"Parquet time (s)\"])\n",
    "\n",
    "df_tempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c46e60",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "This benchmark measures the execution time of a simple aggregation query (`AVG(rating)` grouped by `movieId`) across four scenarios:\n",
    "\n",
    "- CSV 100K\n",
    "- Parquet 100K\n",
    "- CSV 33M\n",
    "- Parquet 33M\n",
    "\n",
    "The results show the strong impact of storage format on query speed, with Parquet providing substantial improvements—especially at larger scales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4aa39",
   "metadata": {},
   "source": [
    "# 4.0 DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d6dc5",
   "metadata": {},
   "source": [
    "## 4.1 Benchmark 2 — Simple COUNT() Query (DuckDB vs Polars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda6b7a",
   "metadata": {},
   "source": [
    "Here we run the same aggregation query (`AVG(rating)` grouped by `movieId`) on Parquet files using DuckDB and Polars, for 100k and 33M rows, in order to compare the execution engines under a simple workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97aa5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths para Parquet\n",
    "\n",
    "p100k = ratings_100k_csv.with_suffix(\".parquet\")\n",
    "p33m = ratings_33m_csv.with_suffix(\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9274a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de benchmark\n",
    "\n",
    "def run_duckdb(path):\n",
    "    t0 = time.time()\n",
    "    duckdb.sql(f\"\"\"\n",
    "        SELECT movieId, AVG(rating)\n",
    "        FROM '{path}'\n",
    "        GROUP BY movieId\n",
    "    \"\"\").df()\n",
    "    return round(time.time() - t0, 3)\n",
    "\n",
    "def run_polars(path):\n",
    "    t0 = time.time()\n",
    "    (\n",
    "        pl.scan_parquet(str(path))     \n",
    "          .group_by(\"movieId\")         \n",
    "          .agg(pl.col(\"rating\").mean())\n",
    "          .collect()\n",
    "    )\n",
    "    return round(time.time() - t0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9e96088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100k</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33m</td>\n",
       "      <td>0.698</td>\n",
       "      <td>1.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  DuckDB (s)  Polars (s)\n",
       "0    100k       0.018       0.040\n",
       "1     33m       0.698       1.828"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparação\n",
    "\n",
    "df_duck_polars = pd.DataFrame([\n",
    "    [\"100k\", run_duckdb(p100k), run_polars(p100k)],\n",
    "    [\"33m\", run_duckdb(p33m), run_polars(p33m)],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_duck_polars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39228",
   "metadata": {},
   "source": [
    "## 4.2 Benchmark 3 — Aggregation + JOIN (AVG, COUNT, STDDEV) — DuckDB vs Polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8707409",
   "metadata": {},
   "source": [
    "This benchmark uses a more realistic analytical workload on the 33M dataset:\n",
    "we compute average rating, number of ratings and standard deviation per movie, join with the movies table to retrieve titles, filter movies with at least 500 ratings, and sort by total_ratings (TOP 100). The goal is to compare DuckDB and Polars under a heavier analytical query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f87774",
   "metadata": {},
   "source": [
    "**DuckDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb451b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths para Parquet (AGORA como string)\n",
    "ratings_33m_parquet = ratings_33m_csv.with_suffix(\".parquet\")\n",
    "movies_33m_parquet  = movies_33m_csv.with_suffix(\".parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8192f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RATINGS = 500\n",
    "\n",
    "def run_duckdb_movie_stats(con):\n",
    "    sql = f\"\"\"\n",
    "    WITH movie_stats AS (\n",
    "        SELECT\n",
    "            m.movieId,\n",
    "            m.title,\n",
    "            AVG(r.rating) AS avg_rating,\n",
    "            COUNT(*) AS total_ratings,\n",
    "            STDDEV_POP(r.rating) AS std_rating\n",
    "        FROM read_parquet('{ratings_33m_parquet.as_posix()}') r\n",
    "        JOIN read_parquet('{movies_33m_parquet.as_posix()}') m USING (movieId)\n",
    "        GROUP BY m.movieId, m.title\n",
    "        HAVING COUNT(*) >= {MIN_RATINGS}\n",
    "    )\n",
    "    SELECT\n",
    "        movieId,\n",
    "        title,\n",
    "        ROUND(avg_rating, 3) AS avg_rating,\n",
    "        total_ratings,\n",
    "        ROUND(std_rating, 3) AS std_rating\n",
    "    FROM movie_stats\n",
    "    ORDER BY total_ratings DESC\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    return con.sql(sql).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14668867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b66992510042e28bf619da3a8b2c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05aa519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bb5450273a48cea6bb5e0f13fbee3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "df_duckdb_stats = run_duckdb_movie_stats(con)\n",
    "t_duckdb_stats = time.perf_counter() - start\n",
    "#df_duckdb_stats.head(), t_duckdb_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad84db",
   "metadata": {},
   "source": [
    "**Polars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4fddad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_polars_movie_stats_33m():\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # usar os ficheiros PARQUET, não os CSV\n",
    "    ratings = (\n",
    "        pl.scan_parquet(str(ratings_33m_parquet))\n",
    "        .select([\"movieId\", \"rating\"])\n",
    "    )\n",
    "\n",
    "    movies  = (\n",
    "        pl.scan_parquet(str(movies_33m_parquet))\n",
    "        .select([\"movieId\", \"title\"])\n",
    "    )\n",
    "\n",
    "    MIN_RATINGS = 500\n",
    "\n",
    "    result = (\n",
    "        ratings\n",
    "        .group_by(\"movieId\")\n",
    "        .agg([\n",
    "            pl.col(\"rating\").mean().alias(\"avg_rating\"),\n",
    "            pl.count().alias(\"total_ratings\"),\n",
    "            pl.col(\"rating\").std().alias(\"std_rating\"),\n",
    "        ])\n",
    "        .filter(pl.col(\"total_ratings\") >= MIN_RATINGS)\n",
    "        .join(movies, on=\"movieId\")\n",
    "        .select([\n",
    "            \"movieId\",\n",
    "            \"title\",\n",
    "            pl.col(\"avg_rating\").round(3),\n",
    "            \"total_ratings\",\n",
    "            pl.col(\"std_rating\").round(3),\n",
    "        ])\n",
    "        .sort(\"total_ratings\", descending=True)\n",
    "        .limit(100)\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    elapsed = time.perf_counter() - start\n",
    "    return result, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97ab636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarac\\AppData\\Local\\Temp\\ipykernel_5312\\1360028000.py:22: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"total_ratings\"),\n"
     ]
    }
   ],
   "source": [
    "df_polars_stats_33m, t_polars_stats_33m = run_polars_movie_stats_33m()\n",
    "#df_polars_stats_33m.head(), t_polars_stats_33m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc776f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DuckDB (s)</th>\n",
       "      <th>Polars (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33M (complex)</td>\n",
       "      <td>3.380861</td>\n",
       "      <td>2.221839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dataset  DuckDB (s)  Polars (s)\n",
       "0  33M (complex)    3.380861    2.221839"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complex = pd.DataFrame([\n",
    "    [\"33M (complex)\", t_duckdb_stats, t_polars_stats_33m],\n",
    "], columns=[\"Dataset\", \"DuckDB (s)\", \"Polars (s)\"])\n",
    "\n",
    "df_complex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90d778",
   "metadata": {},
   "source": [
    "# 5.0 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33b948fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100k</td>\n",
       "      <td>CSV vs Parquet</td>\n",
       "      <td>DuckDB_CSV</td>\n",
       "      <td>0.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100k</td>\n",
       "      <td>CSV vs Parquet</td>\n",
       "      <td>DuckDB_PARQUET</td>\n",
       "      <td>0.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>33M</td>\n",
       "      <td>CSV vs Parquet</td>\n",
       "      <td>DuckDB_CSV</td>\n",
       "      <td>7.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>33M</td>\n",
       "      <td>CSV vs Parquet</td>\n",
       "      <td>DuckDB_PARQUET</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>100k</td>\n",
       "      <td>Simple Test</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>100k</td>\n",
       "      <td>Simple Test</td>\n",
       "      <td>Polars</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>33M</td>\n",
       "      <td>Simple Test</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>0.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>33M</td>\n",
       "      <td>Simple Test</td>\n",
       "      <td>Polars</td>\n",
       "      <td>1.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>33M</td>\n",
       "      <td>Complex Test</td>\n",
       "      <td>DuckDB</td>\n",
       "      <td>3.380861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>33M</td>\n",
       "      <td>Complex Test</td>\n",
       "      <td>Polars</td>\n",
       "      <td>2.221839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Benchmark Dataset        Scenario          Engine  Time (s)\n",
       "0         1    100k  CSV vs Parquet      DuckDB_CSV  0.764000\n",
       "1         1    100k  CSV vs Parquet  DuckDB_PARQUET  0.101000\n",
       "2         1     33M  CSV vs Parquet      DuckDB_CSV  7.435000\n",
       "3         1     33M  CSV vs Parquet  DuckDB_PARQUET  0.890000\n",
       "4         2    100k     Simple Test          DuckDB  0.018000\n",
       "5         2    100k     Simple Test          Polars  0.040000\n",
       "6         2     33M     Simple Test          DuckDB  0.698000\n",
       "7         3     33M     Simple Test          Polars  1.828000\n",
       "8         3     33M    Complex Test          DuckDB  3.380861\n",
       "9         3     33M    Complex Test          Polars  2.221839"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = pd.DataFrame([\n",
    "    [\"1\",\"100k\",\"CSV vs Parquet\", \"DuckDB_CSV\", tempos[\"CSV_100k\"]],\n",
    "    [\"1\",\"100k\",\"CSV vs Parquet\", \"DuckDB_PARQUET\", tempos[\"PARQUET_100k\"]],\n",
    "    [\"1\",\"33M\",\"CSV vs Parquet\", \"DuckDB_CSV\", tempos[\"CSV_33M\"]],\n",
    "    [\"1\",\"33M\",\"CSV vs Parquet\", \"DuckDB_PARQUET\", tempos[\"PARQUET_33M\"]],\n",
    "    [\"2\",\"100k\",\"Simple Test\", \"DuckDB\", df_duck_polars.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"2\",\"100k\",\"Simple Test\", \"Polars\", df_duck_polars.loc[0, \"Polars (s)\"]],\n",
    "    [\"2\",\"33M\",\"Simple Test\", \"DuckDB\", df_duck_polars.loc[1, \"DuckDB (s)\"]],\n",
    "    [\"3\",\"33M\",\"Simple Test\", \"Polars\", df_duck_polars.loc[1, \"Polars (s)\"]],\n",
    "    [\"3\",\"33M\",\"Complex Test\", \"DuckDB\", df_complex.loc[0, \"DuckDB (s)\"]],\n",
    "    [\"3\",\"33M\",\"Complex Test\", \"Polars\", df_complex.loc[0, \"Polars (s)\"]],\n",
    "], columns=[\"Benchmark\",\"Dataset\",\"Scenario\", \"Engine\", \"Time (s)\"])\n",
    "\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352502a",
   "metadata": {},
   "source": [
    "The results show that Parquet is substantially faster than CSV, delivering up to a considerable improvement on the 33M dataset.\n",
    "\n",
    "In the engine comparison (Benchmark 2), DuckDB is consistently faster on simple aggregations, both on the 100k dataset (0.018s vs 0.040s) and the 33M dataset (0.698s vs 1.828s), while Polars remains competitive.\n",
    "\n",
    "In the complex analytical query (Benchmark 3), Polars outperforms DuckDB on the 33M dataset (2.22s vs 3.38s), demonstrating better scalability under heavier workloads.\n",
    "\n",
    "Both engines achieve very efficient performance when operating on Parquet, highlighting the benefits of columnar storage for analytical processing.\n",
    "\n",
    "Overall, Parquet + Polars provides the strongest performance for large-scale analytical queries as dataset size and query complexity increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6885abc",
   "metadata": {},
   "source": [
    "__Close the connection (when done)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a14fde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con.close()\n",
    "#print(\"Connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
